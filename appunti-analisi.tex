\documentclass[11pt]{article}


\input{template/preamble}

\begin{document}

\title{Analisi 2}
\author{Guglielmo Bartelloni}

\maketitle
\tableofcontents
\newpage
\thispagestyle{empty}


\section{Lezione 1}

\subsection{Equazioni differenziali}

Le equazioni differenziali sono equazioni in cui l'incognita è un equazione insieme a qualche sua derivata.

\subsubsection{Equazioni differenziali ordinarie}

Noi vedremo quelle del primo ordine lineari e di secondo ordine con coefficienti costanti

Problema di Cauchy: problema con condizioni iniziali.


\defn{}{Una equazione di ordine n è una equazione del tipo:
\[
    F(x,y(x),y'(x),...,y^{(n-1)}(x),y^{(n)}(x))=0
\]
\[
    x \in I \subseteq \mathbb{R}
\]
dove l'incognita è la qualunque y(x). F è funzione di (n+2) variabili $x,y(x),y'(x)....$
}



L'\textbf{ordine} è dato dal massimo ordine di derivazione che compare.


Per esempio:
\[
    y'''+2y''+5y = e^x
\]
è di ordine 3

\defn{Soluzione (curva) integrale}{La soluzione di una EDO di ordine n sull'intervallo I \[
        (*) F(x,y(x),y'(x),...) = 0
\]
\[
    x \in I \subseteq \mathbb{R}
\]

$\varphi(x)$ che sia definita (almeno) in I e ivi derivabile fino all'ordine n per cui valga (*), ovvero:
\[
    F(x,\varphi(x),\varphi ' (x), ... ) = 0 
\]

$\forall x \in I$

Chiaramente cambia a seconda dell'intervallo
}

\defn{Integrale Generale}{Si chiama integrale \textbf{generale} di (*) in I l'insieme di tutte le soluzioni di (*) in I}


E' possibile definire un espressione piu' esplicita

\defn{Forma normale}{Un edo di ordine n si dice in forma normale se è in forma

    \[
        y^{(n)} = f(x,y(x),y'(x),....,y^{(n-1)}), x \in I
    \]
    
    Esempio:
    \[
        y'''=-5y'+sinx
    \]
    Quella sopra è un EDO di III ordine normale.
}

\defn{EDO di ordine n lineare}{Una EDO di ordine n si dice lineare se è nella forma
    \[
        a_n(x)y^{(n)}(x)+a_{n-1}(x)y^{(n-1)}+... + a_2(x)y''(x)+a_1(x)y'(x)+a_0y(x)=f(x),x \in I
    \]

    Dove le funzioni \[
        a_0(x),a_1(x),a_2(x),...,a_n(x),f(x)
    \]

    sono assegnate (continue) in I

    Esempio:
    \[
        xy''+5y = sin x
    \]

}


Quando $f(x)=0$ allora l'equazione si dice l'\textbf{omogenea associata} 


Nel nostro caso le equazioni di secondo ordine lineari saranno a \textbf{coefficienti costanti}


Vediamo come si risolve il problema della determinazione delle soluzioni di EDO lineari


\subsubsection{I ordine (n=1)}

\[
    F(x,y(x),y'(x))=0
\]

La considero in forma normale:
\[
    (1)\ y'(x)+a(x)y(x)=f(x), x \in [a,b]
\]

dove le funzioni $a(x)$ e $f(x)$ sono continue in $[a,b]$


Se $f(x)=0$ si ottiene omogenea associata:
\[
    (2)\ y'(x)+a(x)y(x)=0
\]

Come si determina l'integrale generale di (1)?

Il teorema che enunciamo vale per tutte le EDO lineari di ordine n

\teorema{}{L'integrale generale di (1) in $[a,b]$ è dato dalla somma dell'integrale generale dell'omogenea associata (2)
con un integrale particolare noto di (1)
\[
\int_{{}}^{{}} {gen} (1) = \int_{{}}^{{}} {gen(2)}  + \int_{{}}^{{}} {particolare} (1)
\]
}

\begin{proof}
    



Sia $y(x)$ una soluzione qualsiasi di (1) ($y(x)$ appartiene all'integrale generale di (1))
e sia $\bar y(x)$ una soluzione particolare (nota) di (1). Voglio far vedere è che la loro differenza è una soluzione qualsiasi di (2)

Dunque per ipotesi n ha che:
\[
    y'(x)+a(x)y(x) = f(x), \forall x \in [a,b]
\]

\[
    \bar y'(x) + a(x) \bar y(x) = f(x)
\]

Entrambe soddisfano la (1)

Sottraggo membro a membro le due:

\[
    y'(x)-\bar y'(x) + a(x)y(x) - a(x) \bar y(x) = f(x) - f(x)
\]

\[
    y'(x)-\bar y'(x) + a(x)[y(x) - \bar y(x)]=0
\]

Si può scrivere anche (le derivate raccolte):
\[
    [y(x)-\bar y(x)]' + a(x)[y(x) - \bar y(x)]=0
\]

E dunque  la funzione $y(x) - \bar y(x) = z(x)$ è soluzione di (2)
Quindi:
\[
    y(x) = \bar y(x) + z(x)
\]

Viceversa se $z(x)$ è una qualsiasi soluzione di (2) e $\bar y(x)$ è una soluzione particolare di (1) 
voglio mostrare che la loro somma è soluzione di (1)

Pongo:
\[
    y(x) = z(x) + \bar y(x)
\]

Devo mostrare che $y(x)$ verifica (1)

sapendo che:
\[
    z'(x) + a(x)z(x) = 0
\]

\[
    \bar y'(x) + a(x) \bar y(x) = f(x)
\]

\[
    y'(x) = (z(x) + \bar y(x) )' = z'(x) + \bar y'(x) =
    -a(x)z(x)-a(x)\bar y(x) + f(x) = -a(x) [z(x) + \bar y(x)] +f(x)
\]

E quindi ho dimostrato che:
\[
    y'(x) = -a(x)y(x) + f(x)
\]

\[
    y'(x) +  a(x)y(x) = f(x)
\]

\[
    y(x) = z(x) + \bar y(x)
\]

\end{proof}


\section{Lezione 2}
\subsection{Facciamo vedere che il teorema precedente valeva anche per $n>1$}

Supponiamo che $u$ e $v$ siamo due soluzioni di (1), cioè che:

$Lu=f$ e $Lv=f$ su $I$

La differenza di queste diventano soluzione su $I=[a,b]$ dell'omogenea associata

Usando la propietà della linearità:

\[
    L(\lambda u+\mu v) = \lambda L u + \mu L v
\]

\[
    L(u-v) = Lu-Lv = f- f=0
\]

Se indichiamo con $V_0$ l'insieme di tutte le soluzioni dell'equazione omogenea associata ($Lw=0$ su $I=[a,b]$ e $V_0$ è l'insieme delle $w \in \mathbb{C}^n(I)$) e con $\bar u(t)$ una soluzione nota di (1)

\[
    u(x) = \bar u(x) +w(x)
\]

L'uguaglianza sopra, al variare di $w(x)$ in $V_0$ ci da tutte le soluzioni del problema di partenza. 

(Il problema quindi, diventa solo di studiare il problema omogeneo)

\subsection{Torniamo al I ordine}

Adesso ritorniamo al problema di I ordine (in forma normale):

\[
    (1)\ y'(x)+a(x)y(x)=f(x)
\]

dove $a()$ e $f()$ sono continue su $[a,b]$

\[
    (2)\ y'(x)+a(x)y(x)=0
\]

Secondo il teorema della prima lezione:

\[
    y(x)=z(x)+\bar y(x)
\]

Come si determina l'insieme di tutte le soluzioni (integrale generale) di (2), cioè:

\[
    (2)\ y'(x)+a(x)y(x)=0,x \in [a,b]
\]

Sia $A(x)$ una \textbf{primitiva} di $a(x)$:

\[
    A(x) = \int_{{}}^{{}} {a(x)} \: d{x} {}
\]

Moltiplichiamo i due membri della (2) per $e^{A(x)}$:

\[
    e^{A(x)} y'(x) + e ^{A(x)}a(x) y(x)=0, x \in [a,b]
\]

La posso scrivere anche (la derivata di $e ^{A(x)}y(x)$):

\[
    (e ^{A(x)} y(x))' = e ^{A(x)}a(x)y(x) + e ^{A(x)}y'(x)
\]

quindi (sempre chiaramente nell'intervallo $[a,b]$):

\[
    (e ^{A(x)}y(x))'=0
\]

Questo mi dice che:

\[
    e ^{A(x)}y(x) = costante=c \in \mathbb{R}
\]

porto dall'altra parte:

\[
    y(x) = c e ^{-A(x)}
\]

espandendo $A(x)$:

\[
    y(x) = c e ^{\int_{{}}^{{}} {a(x)} \: d{x} {}}
\]

posso considerare le soluzioni come:

\[
    y(x) = c z_0
\]

dove $z_0$ è una soluzione particolare di (2).

Infatti $e ^{-A(x)}$ è soluzione di (2)

\begin{proof}
    \[
    e ^{-A(x)} = -a(x) e ^{-A(x)}
\]

ovvero

\[
    (e ^{-A(x)})'+a(x) e ^{-A(x)}=0
\]
    
\end{proof}


\subsubsection{Determinazione dell'integrale particolare}

Sappiamo:

\[
    (1)\ y'(x)+a(x)y(x)=f(x)
\]

\[
    (2)\ y'(x)+a(x)y(x)=0
\]

Cerco l'integrale particolare ad \textbf{occhio} oppure uso il \textbf{metodo della variazione della costante}

\paragraph{Metodo della variazione della costante}

Cerco questa $c(x)$ in questa forma:

\[
    \bar y(x) = c(x) e ^{-A(x)}
\]

Ovviamente la cerco dopo che so che $\bar y(x)$ è soluzione del problema.

\begin{proof}
    Poichè $\bar y(x)$ è soluzione di (1) si ha che $\bar y'(x)+a(x) \bar y(x)=f(x)$ da cui sostituendo $\bar y(x) = c(x) e ^{-A(x)}$:

    \[
        (c(x) e ^{-A(x)})'+ a(x) c(x) e ^{-A(x)} = f(x)
    \]
    
    Deriviamo:

    \[
        c'(x) e ^{-A(x)} - c(x) a(x) e ^{-A(x)} + a(x) c(x) e ^{-A(x)}= f(x)
    \]
    
    semplifico

    \[
        c'(x) e ^{-A(x)} = f(x)
    \]

    \[
        c'(x) = f(x) e ^{A(x)} \rightarrow c(x) = \int_{{}}^{{}} {f(x) e ^{A(x)}} \: d{} {}
    \]

    e dunque:

    \[
        \bar y(x) = e ^{-A(x)} \int_{{}}^{{}} {f(x) e ^{A(x)}} \: d{x} {}
    \]

    Cioè l'integrale particolare
\end{proof}

Se metto tutto insieme l'integrale generale diventa:

\[
    y(x) = c e ^{-A(x)} + e ^{-A(x)} \int_{{}}^{{}} {f(x) e ^{A(x)}} \: d{x} {}
\]

\subsubsection{Osservazioni sulla formula}

$A(x)$ è \textbf{una} primitiva di $a(x)$ scelta una volta per tutte.

\textbf{Non} occorre mettere una costante arbitraria (ovvero considerare come $A(x) + K,K \in \mathbb{R}$ ) poiche l'integrale generale non cambia

\textbf{Non} serve neanche nell'integrale perchè verrebbe buttato dentro $c$ dell'integrale generale


\subsubsection{Esempi}

\[
    y'(x) = 5y(x) + e ^{x}
\]

in questo caso $a(x) = -5$

\[
    A(x) = - \int_{{}}^{{}} {5} \: d{x} {}=-5x
\]

Quindi: 

\[
    e ^{-A(x)}=e ^{5x}
\]

\[
    y(x) = c e ^{5x} + e ^{5x} \int_{{}}^{{}} {e^x e ^{-5x}} \: d{x} {} = c e ^{5x} + e ^{5x} \int_{{}}^{{}} {e ^{-4x}} \: d{} {} = c e ^{5x} + e ^{5x} (\frac{1}{4} e ^{-4x}) = c e ^{5x} - \frac{1}{4} e ^{x}
\]

Esercizio per casa:

\[
    u' + \frac{u}{t} = e ^{t}
\]

\section{Lezione 3}

Solitamente si suppongono delle condizioni iniziali nel risolvere le equazioni differenziali (problema di Cauchy).

\begin{equation}
    \begin{cases}
      y'(x)+a(x)y(x)=f(x)\\
      y(x_0)=y_0
    \end{cases}\,.
\end{equation}

Praticamente gli integrali della formula generale diventano definiti tra $x_0$ e $x$.

Quindi:

\[
    y(x) = ce ^{-A(x)}+ e ^{-A(x)} \int_{{}}^{{}} {e ^{A(x)}f(x)} \: d{x} {} = c e ^{-\int_{{x_0}}^{{x}} {a(t)} \: d{t} {}}+e ^{- \int_{{x_0}}^{{x}} {a(t)} \: d{t} {}}\int_{{x_0}}^{{x}} {e ^{\int_{{x_0}}^{{s}} {a(t)} \: d{t} {}}f(s)} \: d{s} {}\\
\]

\[
    y(x_0)=y_0=c
\]


Voglio trovare la soluzione generale in questo caso, parto dall'omogenea:

\[
    y'+x(x)y(x) = 0
\]

\[
    e ^{\int_{{x_0}}^{{x}} {a(x)} \: d{t} {}} = e ^{A(x)}
\]


\subsection{Il problema di Cauchy}

Quindi introduciamo il problema di Cauchy:

\begin{equation}
    \begin{cases}
      y'+a(x)y = f(x)\\
      y(x_0) = y_0
    \end{cases}\,.
\end{equation}

dove $x \in I = [a,b]$ e $x_0 \in I$

con le ipotesi fatte ($a(x)$ e $f(x)$ continue in I) ha una e una sola soluzione (SOLUZIONE UNICA)

con l'espressione esplicita determinata.

\textbf{Esempio 1}

Determinare la soluzione del problema di Cauchy:

\begin{equation}
    \begin{cases}
      y'(x)=5y(x) + e ^{x}\\
      y(0)=0
    \end{cases}\,.
\end{equation}

\[
    A(x)=\int_{{0}}^{{x}} {a(t)} \: d{t} {}= - \int_{{0}}^{{x}} {5} \: d{t} {}= -5x
\]

\[
    y(x)=0e ^{5x} + e ^{5x}\int_{{0}}^{{x}} {e ^{-5t}e ^{t}} \: d{t} {}=
\]

\[
    = e ^{5x} \Eval{[ -\frac{1}{4} e ^{-4t}]}{0}{x} = e ^{5x}(-\frac{1}{4} e ^{-4x}+\frac{1}{4})= - \frac{1}{4} e ^{x}+ \frac{1}{4} e ^{5x}
\]

\textbf{Esempio 2}

Determinare l'integrale generale della EDO:

\[
    y'+\frac{1}{\sqrt{x}} y=1
\]

e trovare le eventuali soluzioni tali che:

\[
    \lim_{x \to \infty} y(x) = +\infty
\]

Soluzione: 

l'equazione è definita per ogni $x>0$

\[
    a(x) = \frac{1}{\sqrt{x}} 
\]

\[
    A(x) = \int_{{}}^{{}} {\frac{1}{\sqrt{x}} } \: d{x} {}
\]


L'integrale generale:

\[
    y(x) = c e ^{-\int_{{}}^{{}} {\frac{1}{\sqrt{x}} } \: d{x} {}}+ e ^{-\int_{{}}^{{}} {\frac{1}{\sqrt{x}} } \: d{x} {}}( \int_{{}}^{{}} {e ^{\int_{{\frac{1}{\sqrt{x}} }}^{{}} {} \: d{x} {+1}}} \: d{x} {})=
\]

\[
    =e ^{2 \sqrt{x}} (e+ \int_{{}}^{{}} {e ^{2\sqrt{x}}} \: d{x} {})
\]

Risolvo l'integrale pongo $t = 2 \sqrt{x}$ quindi $ dt = \frac{1}{\sqrt{x}}dx \rightarrow dx = \frac{t}{2} dt $:

\[
    \int_{{}}^{{}} {e ^{2 \sqrt{x}}} \: d{x} {}= \int_{{}}^{{}} {e ^{t}\frac{t}{2} } \: d{t} {} = e ^{x}\frac{t}{2} - \int_{{}}^{{}} {e ^{t}\frac{1}{2} } \: d{t} {}=
\]

\[
    = e ^{t} \frac{t}{2} - \frac{1}{2 e ^{t}} 
    \overset{\text{risostituisco}}{=} e ^{2 \sqrt{x}} \frac{2 \sqrt{x}}{2} - \frac{1}{2} e ^{2 \sqrt{x}}
\]

Ora riscrivo l'integrale generale:

\[
    y(x) = e ^{-2 \sqrt{x}}[ c + e ^{2 \sqrt{x}}(\sqrt{x}- \frac{1}{2} )]= c e ^{-2 \sqrt{x}}+ \sqrt{x} - \frac{1}{2} 
\]

Adesso soddisfo la richiesta (quali sono le soluzioni che vanno all'infinito)

\[
    \lim_{x \to \infty} c ^{-2 \sqrt{x}} + \sqrt{x} - \frac{1}{2} = +\infty
\]

questo vale per $\forall c \in \mathbb{R}$


\textbf{Esempio 3}

\begin{equation}
    \begin{cases}
      y' + \frac{2y}{x} = \frac{1}{2} \\
      y(-1)=2
    \end{cases}\,.
\end{equation}

Considero l'intervallo dove sta il $x_0=-1$ quindi $(-\infty,0)$

\[
    A(x) = \int_{{-1}}^{{x}} {\frac{1}{t} } \: d{t} {} = \Eval{[2 log|t|]}{-1}{x} = 2 log|x| - 2 log|-1| = 2 log|x| = 
\]

per via dell'intervallo il valore assoluto viene preso col meno:

\[
    =2 log(-x)  
\]

quindi l'integrale generale:

\[
    y(x) = 2 e ^{-2log(-x)}+ e^{-2log(-x)}(\int_{{-1}}^{{x}} {e ^{2log(-t)}\frac{1}{t ^{2}} } \: d{t} {})=
\]

uso la proprietà dei logaritmi:

\[
    = 2 e ^{log \frac{1}{x ^{2}} }+ e ^{log \frac{1}{x ^{2}} }\int_{{-1}}^{{x}} {e ^{log t ^{2}}} \: d{t} {}= \frac{2}{x ^{2}} + \frac{1}{x ^{2}} \int_{{-1}}^{{x}} {1} \: d{t} {} = \frac{2}{x ^{2}} + \frac{1}{x ^{2}} \Eval{[t]}{-1}{x} 
     = \frac{2 }{x ^{2}} + \frac{1}{x ^{2}} (x+1)
\]




\section{Lezione 4}

\subsection{Edo a variabili separabili}

Una edo si dice a variabili separabili se è della forma:

\[
    y'(x) = f(x) g(y(x))
\]

Parte che dipende da y viene moltiplicata a quella che dipende da x.

Dove le funzioni f e g sono continue nei loro domini di definizione

Il procedimento per risolverle è il seguente:

\begin{enumerate}
    \item Si cercano le soluzioni costanti $g(y)=0$ (cioè gli zeri)

        Si determinano gli eventuali $\bar y$ reali t.c. $g(\bar y)$

        $y(x)= \bar y$ sono soluzioni singolari del problema 
        
    \item Se $y \neq \bar y$ si procede separando le variabili, ovvero dividiamo per $g(y)$
\end{enumerate}

E quindi alla fine abbiamo:

\[
    \frac{y'(x)}{g(y(x))} = f(x) \overset{\text{integro rispetto ad x}}{=} \int_{{}}^{{}} {\frac{y'(x)}{g(y(x))} } \: d{x} {} = \int_{{}}^{{}} {f(x)} \: d{x} {}
\]

Uso la sostituzione $y = y(x)$ e $dy = y'(x) dx$:

\[
    \int_{{}}^{{}} {\frac{1}{g(y)} } \: d{y} = {\int_{{}}^{{}} {f(x)} \: d{x} {}}
\]

Chiamate $G$ e $F$ una primitiva di $\frac{1}{g} $ e di $f$ rispettivamente:

\[
    G(y(x)) = F(x) + c
\]

Applico la funzione inversa di $G$ ad entrambi i membri per scrivere esplicitamente la soluzione:

\[
    y(x) = G ^{-1} (F(x) + c)
\]

\textbf{Esempio}

Determinare tutte le soluzioni dell'equazione differenziale:

E' non lineare

\[
    y'(x) = (1-y)(2-y)x
\]

Le prime due parentesi sono $g(y)$ il resto $f(x)$

\begin{enumerate}
    \item Trovare le soluzioni costanti

        Pongo $y'(x) = 0 $:

        \[
            (1-y)(2-y) = 0
        \]

        quindi $y=1$ e $y=2$

    \item Cerchiamo le altre soluzioni dividendo per $g(y)$

        \[
            \frac{y'(x)}{1-y(x)(2-y(x))} = x
        \]

        Quindi integro:

        \[
            \int_{{}}^{{}} {\frac{1}{(1-y)(2-y)} } \: d{y} {}= \int_{{}}^{{}} {x} \: d{x} {}
        \]

        Uso i fratti semplici per risolvere il primo membro:

        \[
            \frac{A}{1-y} + \frac{B}{2-y} = \frac{1}{(1-y)(2-y)} 
        \]

        \[
            A(2-y)+B(1-y) = 1
        \]

        \[
            (-A -B) y +2A + B = 1
        \]

        \begin{equation}
            \begin{cases}
              -A -B = 0\\
              2A+B= 1
            \end{cases}\,.
        \end{equation}

        $A=1$ e $B=1$
        
        Quindi:

        \[
            \int_{{}}^{{}} {\frac{1}{1-y}} \: d{y} {}- \int_{{}}^{{}} {\frac{1}{2-y} } \: d{y} {} = \int_{{}}^{{}} {x} \: d{x} {}
        \]

        \[
            -log|1-y| + log|2-y| = \frac{x ^{2}}{2} +c
        \]

        \[
            log|\frac{2-y}{1-y} | = \frac{x ^{2}}{2} +c
        \]

        Adesso devo esplicitare per $y$ quindi passo agli esponenziali:

        \[
            |\frac{2-y}{1-y} | = e^{(\frac{x ^{2}}{2} +c)}
        \]

        \[
            |\frac{2-y}{1-y} | = e^{(\frac{x ^{2}}{2})} e ^{c} = c_1 e ^{\frac{x ^{2}}{2} } >0
        \]

        Tolgo il valore assoluto:

        \[
            \frac{2-y}{1-y} = \pm c_1 e ^{\frac{x ^{2}}{2} }\overset{\text{usando un'altra costante}}{=}c_2 e ^{\frac{x ^{2}}{2} }
        \]

        \[
            \frac{2-y}{1-y} = c_2 e ^{\frac{x ^{2}}{2} }
        \]

        Con $c_2 \in \mathbb{R}$

        Noi vogliamo trovare la $y(x)$ (per semplicita pongo $c_2 = c$):

        \[
            \frac{2-y}{1-y} = c e ^{\frac{x ^{2}}{2} }
        \]

        Porto di la il denominatore:

        \[
            2-y = c ^{\frac{x ^{2}}{2} } (1-y)
        \]

        Porto di la le cose:

        \[
            (c e ^{\frac{x ^{2}}{2} })y = c ^{\frac{x ^{2}}{2} }-2
        \]

        E quindi le due soluzioni (quella costante e quella non) sono:

        \begin{equation}
            \begin{cases}
            y(x) = \frac{c e ^{\frac{x ^{2}}{2} }-2}{c e ^{\frac{x ^{2}}{2} }-1}   \\
            y=1
            \end{cases}\,.
        \end{equation}

\end{enumerate}

\textbf{Esercizio Problema di Cauchy}

Risolviamo ora il problema:

\begin{equation}
    \begin{cases}
      y'=(1-y)(2-y)x\\
      y(0)=3
    \end{cases}\,.
\end{equation}

e decidiamo qual è il piu ampio intervallo su cui è definita la soluzione

Avendo già risolto la EDO imponiamo la condizione $y(0) = 3$:

\[
    y(0) = \frac{c-2}{c-1} = 3
\]

\[
    c-2 = 3c -3
\]

\[
    c = \frac{1}{2} 
\]

La soluzione del problema è quindi (sostituisco la c trovata all'equazione):

\[
    y(x) = \frac{\frac{1}{2} e ^{\frac{x ^{2}}{2} }-2}{\frac{1}{2} e ^{\frac{x ^{2}}{2} }-1} 
\]

\[
    y(x) = \frac{ e ^{\frac{x ^{2}}{2} }-4}{ e ^{\frac{x ^{2}}{2} }-2} 
\]

La soluzione è definita nel piu ampio intervallo contenente $x_0 = 0 $ ( per cui l'esressione ha senso) nel nostro caso il denominatore $\neq 0$

\[
    e ^{\frac{x ^{2}}{2} } - 2 \neq 0
\]

\[
    e ^{\frac{x ^{2}}{2} }  \neq 2
\]

\[
    x ^{2} \neq 2 log 2
\]

\[
    x \neq \pm \sqrt{2 log2}
\]

Quindi l'intervallo piu ampio è quello che contiene zero ed è compreso tra le regole che abbiamo appena trovato:

\[
    0 \in (-\sqrt{2log2},+\sqrt{2log2}) 
\]

Osserviamo che la soluzione:

\[
    y(x) = \frac{ e ^{\frac{x ^{2}}{2} }-4}{ e ^{\frac{x ^{2}}{2} }-2} 
\]

è definita $\forall x \in \mathbb{R}$ con $x \neq \pm \sqrt{2log2}$


Il motivo per cui la soluzione del problema di Cauchy è definita su un intervallo si capisce bene se si pensa al significato fisico del nostro problema:

\begin{equation}
    \begin{cases}
        \text{x tempo}\\
        \text{y(x) evoluzione del sistema}\\
        \text{condizione iniziale}
    \end{cases}\,.
\end{equation}

Se partendo dall'istante iniziale ($x_0$) e procedendo in avanti o a ritroso nel tempo troviamo un istante per cui il sistema non esiste (nel caso di prima $\pm \sqrt{2log2}$) la $y(x)$ non esiste piu, non ha senso domandarsi che cosa succede oltre quell'istante

Se lo vedo dal punto di vista matematico se accettassimo soluzioni definite su intervalli disgiunti non avremmo piu l'unicità della soluzione (ce ne sarebbero 3 nel nostro caso e non una come volevo) perche avremmo rami distinti della funzione $y(x)$ definiti su intervalli disgiunti che non si raccordano tra di loro, dunque la condizione iniziale $y(x_0) = y_0$ non determina i valore della funzione $y(x)$ negli intervalli che non contentgono l'istante iniziale $x_0$

\begin{itemize}
    \item \textbf{ Soluzione in piccolo (locale) } (è definita in un intorno di $x_0$)
    \item \textbf{ Soluzione in grande (globale) } (è definita in tutto l'intervallo)
\end{itemize}

\textbf{Esercizio per casa}

\begin{equation}
    \begin{cases}
      y'(x) = xy(x)+2x\\
      y(0) = 1
    \end{cases}\,.
\end{equation}

\textbf{Soluzione} 

Raccolgo: 

\[
    y'(x)=x(y+2)
\]

Trovo le soluzioni stazionarie:

\[
    y+2=0
\]

\[
    y=-2
\]

Trovo le altre:

\[
    \int_{}^{} {\frac{1}{y+2}} \: dy = \int_{}^{} {x} \: dx 
\]

\[
    y+2 = c e ^{ \frac{x^{2}}{2}}+c
\]

Impongo le condizioni di Cauchy e trovo c sostituendo:

\[
    y=3e ^{ \frac{x^{2}}{2}}-2
\]

Quindi la soluzione completa e':

    \begin{equation}
        \begin{cases}
            y=-2\\
            y=3e ^{ \frac{x^{2}}{2}}-2
        \end{cases}\,.
    \end{equation}



\subsection{EDO lineari del II ordine}

\[
    a_2(x)y''(x) + a_1(x) y'(x) + a_0(x) y(x) = f(x)
\]

con $a_0(),a_1(),a_2(),f()$ continue in I

In forma normale:

\[
    y''(x) + a(x) y'(x) + b(x)y(x) = f(x)
\]

se pongo $f(x) = 0$ ho la omogenea associata (2)

le sue soluzioni sono linearmente indipendenti

Se abbiamo due soluzioni $y_1$ e $y_2$ di:

\[
    a_2(x)y''(x) + a_1(x) y'(x) + a_0(x) y(x) = 0
\]

Poniamo:

\[
    y(x) = c_1 y_1(x) + c_2 y_2(x)
\]

io so che le soluzioni soddisfano l'equazione (per definizione):

\[
    a_2(x)y_1''(x) + a_1(x) y_1'(x) + a_0(x) y_1(x) = 0
\]

\[
    a_2(x)y_2''(x) + a_1(x) y_2'(x) + a_0(x) y_2(x) = 0
\]

adesso:

\[
    y(x) = c_1 y_1(x) + c_2 y_2(x)
\]

Derivo due volte:

\[
    y'(x) = c_1 y_1'(x) + c_2 y_2'(x)
\]

\[
    y''(x) = c_1 y_1''(x) + c_2 y_2''(x)
\]

\[
    a_2(x) [ c_1y_1''(x) + c_2 y_2 ''(x) ] + a_1(x)[ c_1 y_1'(x) + c_2 y_2'(x) ] + a_0(x) [ c_1 y_1(x) + c_2 y_2(x)]= 
\]

\[
    = c_1[a_2(x) y_1''(x) + a_1(x) y_1'(x) + a_0(x) y_1(x)] + c_2 [a_2(x) y_2''(x) + a_1(x) y_2'(x) + a_0(x) y_2(x)] \overset{\text{dato che è soluzione}}{=} 0
\]

\subsection{Lineare indipendenza}


$y_1(x)$ e $y_2(x)$ sono linearmente indipendenti su I se:

\[
    c_1y_1(x) +c_2y_2(x) = 0 \Leftrightarrow c_1=c_2=0
\]

\textbf{Esercizi per Casa} 

\textbf{Esercizio 1}

\[
    y(x) = ce ^{x^{2}-x}+e ^{x^{2}-x}\int_{}^{} {xe ^{x}} \: dx = c e ^{x^{2}-x}+xe ^{x^{2}}-e ^{x^{2}}
\]

Ponendo le condizioni di Cauchy:

\[
    y(0)=2
\]

La soluzione e':

\[
    2 e ^{x^{2}-x}+xe ^{x^{2}}-e ^{x^{2}}
\]

\textbf{Esercizio 2} 

\[
    y'=\sqrt[3]{x}y^{2}
\]

Una soluzione e':

\[
    y=0
\]

Le altre le trovo facendo l'integrale di:

\[
    \int_{}^{} { \frac{1}{y^{2}}} \: dy = \int_{}^{} {\sqrt[3]{x}} \: dx  
\]

quindi $y(x)$:

\[
    y(x)  = \frac{4}{3 \sqrt[3]{x^{4}}+c}
\]

impongo le condizioni e trovo c:

\[
    y(0) = \frac{-4}{0+c} = 2
\]

quindi:

\[
    c = -2
\]

ergo il la soluzione e':

\[
    y(x) = -\frac{4}{3 \sqrt[3]{x^{4}} - 2}
\]

il denominatore deve essere $\neq 0$:

\[
3 \sqrt[3]{x^{4}} - 2 \neq 0
\]

quindi:

\[
    x \neq (\frac{2}{3}^{ \frac{3}{4}})
\]

Il piu ampio intervallo e':

\[
    0 \in (-\infty, \frac{2}{3}^{ \frac{3}{4}}) 
\]

\section{Lezione 5}

Ritorniamo alle equazione del secondo ordine.

\[
    a_2(x)y''(x) + a_1(x) y'(x) + a_0(x) y(x) = f(x)
\]

con $a_0(),a_1(),a_2(),f()$ continue in I $ \in  [a,b]$

ci conentriamo nel caso in cui le $a$ sono costanti (coefficienti costanti).

L'altra volta abbiamo dimostrato che se abbiamo due soluzioni $y_1$ e $y_2$ esse sono linearmente indipendenti cioe' il determinante della matrice di $y_1(x)y_2'(x)-y_2(x)y_2'(x)$ e' diverso da 0 (determinante Wronskiano)

Se quindi l'equazione ha coefficienti costanti diventa:

\[
    ay''(x)+by'(x)+cy(x) = f(x)
\]

con $a,b,c \in \mathbb{R}$ con $a \neq 0$ se no non sarebbe di ordine II, $f(x)$ e' continua in I

Adesso associamo il problema omogeneo:

\[
    ay''(x) + by'(x) + cy(x) = 0
\]

\textbf{Numeri complessi} 

Qui dobbiamo introdurre i numeri complessi perche ci servono per la soluzione, di solito questi sono formati da una parte reale e una parte immaginaria:

\[
    z = \alpha + i\beta
\]

$z$ puo essere scritto come coppia $(\alpha,\beta)$ ad $i$ assegno $i=\sqrt{-1}$

Tornando a noi vediamo il caso in cui $b=c=0$

\[
    ay''(x) = 0
\]

in I ed in particolare:

\[
    y''(x) = 0, \forall x \in I
\]

\[
    y'(x) = c, c \in \mathbb{R}
\]

\[
    y(x) = c_1x+c_0,c_1,c_0 \in \mathbb{R}
\]

Questo caso e' facile. Se invece $b$ e $c$ non sono contemoporaneamente nulli, devo considerare la sequente eq. algebrica di secondo grado:

\[
    p(\lambda) = a \lambda^{2}+b \lambda + c =0
\]

La sua equazione associata a (2):

\[
    p(\lambda) =0 \Leftrightarrow  a \lambda^{2}+b \lambda + c =0, in\ \mathbb{C}
\]

\teorema{Teorema fondamentale dell'algebra}{
    L'equazione di II in $\mathbb{C}$ 

    \[
   a \lambda^{2}+b \lambda + c =0, in\ \mathbb{C}
    \]

    ha sempre due soluzioni in $\mathbb{C}$

}


\textbf{Proposizione} 

$y(x) = e ^{\lambda x}$ e' soluzione di (2) $\Leftrightarrow $ $\lambda$ e' soluzione (radice) di $p(\lambda)=0$ dell'equazione caratteristica associata a (2)

Indico con $Ly$ l'equazione $Ly= ay''+by'+cy$

\begin{proof}
    y e' soluzione di (2) $\Leftrightarrow$ $Ly=0$ 

    Se considero $y(x) = e ^{\lambda x}$ 

    Devo dimostrare che:

    \[
        L(e ^{\lambda x}) = 0 \Leftrightarrow  p(\lambda) = 0
    \]

    Sostituisco ad $x$ $e ^{\lambda x}$:

    \[
        L(e ^{\lambda x}) = a( e^{\lambda x})'' + b( e ^{\lambda x})' + c(e ^{\lambda x}) =
    \]

    \[
        =a \lambda ^{2} e ^{\lambda x} + b \lambda e ^{\lambda x} + c e^{\lambda x}= e ^{\lambda x}(a \lambda ^{2}+ b \lambda+ c)
    \]

    dunque

    \[
        L( e ^{\lambda x}) = 0 \Leftrightarrow a \lambda ^{2}+ b \lambda +c = 0 
    \]
           
\end{proof}


Adesso che ho dimostrato il mio problema e' trovare le radici $p(\lambda) =0$ ($a \lambda ^{2} + b \lambda + c$):

Di solito le soluzioni di secondo grado si scrivono

\[
    \lambda_{1,2} = \frac{-b \pm \sqrt{b ^{2}-4 ac}}{2a}
\]
   
Le soluzioni $\lambda_1$ e $\lambda_2$ sono soluzioni di ((2) $e ^{\lambda_1x}$ e $e ^{\lambda_2x}$)

Distinguiamo tre casi per le soluzioni:

\begin{enumerate}
    \item soluzioni reali e distinte ($\Delta >0$)
    \item soluzioni reali e coincidenti ($\Delta = 0$)
    \item soluzioni complesse coniugate ($ \Delta <0$)
\end{enumerate}

1) $y_1(x) = e ^{\lambda_1x}$ e $y_2(x) = e ^{\lambda_2x}$ con $\lambda_1 e \lambda_2$ $\in \mathbb{R}$ con $\lambda_1 \neq \lambda_2$


2) $y_1(x) = e ^{\lambda x}$ e $y_2(x) = xe ^{\lambda x}$ con $\lambda = - \frac{b}{2a}=\lambda_1=\lambda_2$ $\in \mathbb{R}$ 

3) $y_1(x) = e ^{\alpha x} cos \beta x$ e $y_2(x) = e ^{\alpha x} sin \beta x$ 

questo caso corrisponde a soluzioni complesse coniugate  

\[
    \lambda_1 = \alpha- i \beta \in \mathbb{C} 
\]

\[
    \lambda_2 = \alpha+ i \beta \in \mathbb{C} 
\]

\[
    \lambda = \frac{-b \pm \sqrt{-(4ac-b^{2})}}{2a} = \frac{-b \pm \sqrt{-1(4ac - b^{2})}}{2a} \overset{\text{perche i} = \sqrt{-1}}{=} \frac{-b \pm  \sqrt{4ac -b^{2}}i}{2a} = \alpha \pm i \beta
\]

dove $\alpha = -\frac{b}{2a}$ e $\beta = \frac{\sqrt{4ac - b^{2}}}{2a} >0$


\teorema{}{L'integrale generale dell'equazione omogenea $a y''+by'+c=0$ e' dato da:

    \[
        c_1 y_1(x) + c_2 y_2(x)
    \]

    al variare di $c_1,c_2 \in \mathbb{R}$ dove $y_1(x)$ e $y_2(x)$ sono definite come sopra
}

\begin{proof}
       1) $b^{2}-4ac >0$ con $\lambda_1,\lambda_2$ soluzioni dell'equazioni di $p(\lambda)=0$    

       scrivo la wronskiana di $y_1,y_2$:
       \[
        \begin{bmatrix}
            
        e ^{\lambda_1 x} & e ^{\lambda_2 x} \\
        \lambda_1e ^{\lambda_1 x} & \lambda_2e ^{\lambda_2 x} \\
        
        \end{bmatrix}
       \]
        che e' diverso da zero quindi le soluzioni sono linearemente indipendenti

        sia ora $y(x)$ una soluzione di (2):

        \[
            y(x) = e ^{\lambda_1 x}u(x)
        \]

        io devo determinare $u(x)$ per poi dimostrare che $y(x) = c_1e ^{\lambda_1 x}+c_2 e^{\lambda_2 x}$

        Poiche $y(x) = e ^{\lambda_1 x}u(x)$ e' soluzione di (2) si ha derivando e sostituendo:

        \[
            a( e ^{\lambda_1 x} u(x))'' + b(e ^{\lambda_1 x}u(x))'+ c e ^{\lambda_1 x}u(x) =0
        \]

        \[
            a(\lambda_1 e ^{\lambda_1 x} u(x)+ e ^{\lambda_1 x}u'(x))' + b(\lambda_1e ^{\lambda_1 x}u(x) + e ^{\lambda_1 x}u'(x))+ c e ^{\lambda_1 x}u(x) =0
        \]

        \[
            e ^{(\lambda_1 x}[a \lambda_1 ^{2} + b \lambda_1+c)u(x)+(au''(x)+(2a \lambda_1 + b)u'(x))]=0
        \]

        estraggo solo l'ultima parentesi e impongo che sia uguale a zero perche il resto e' gia zero

        \[
            au''(x) + (2a \lambda_1 + b) u'(x) = 0
        \]

        divido per a:

        \[
            u''(x) +(2 \lambda_1 + \frac{b}{a}) u'(x) = 0
        \]

        sapendo che:

        \[
            a \lambda^{2} + b \lambda + c =0
        \]

        \[
             \lambda^{2} + \frac{b}{a} \lambda + \frac{c}{a} =0
        \]

        \[
            \lambda_1 + \lambda_2 = -\frac{b}{a}
        \]

        \[
            \lambda_1  \lambda_2 = \frac{c}{a}
        \]

        \[
            u''(x) + (2 \lambda_1 - \lambda_1 - \lambda_2)u'(x) = 0
        \]

        il meno per comodita:

        \[
            u''(x) - (\lambda_1 - \lambda_2)u'(x) = 0
        \]

        se adesso chiamo $u'(x)=v(x)$ e $v''(x) = u'(x)$ l'equazione diventa:

        \[
            v' -kv = 0
        \]

        Risolvendo 

        \[
            v(x) = ce ^{kx}
        \]

        \[
            v(x) = c e^{(\lambda_2 - \lambda_1)x}
        \]

        Risostitendo:

        \[
            u'(x) = c e ^{(\lambda_2- \lambda_1)x}
        \]

        Integrando:

        \[
            u(x)  = c_1 e ^{(\lambda_2 - \lambda_1)x}+c_2
        \]
        
        la nostra $y(x)$ diventa:

        \[
            y(x) = e ^{\lambda_1 x}u(x) = e ^{\lambda_1 x}( c_1 e ^{(\lambda_2 - \lambda_1)x}+c_2) = c_1 e ^{\lambda_2 x}+ c_2 e ^{\lambda_1 x}
        \]


\end{proof}

Questo era per il caso 1). Adesso voglio per il caso 2)

\[
    \lambda_1 = \lambda_2 = \lambda = -\frac{b}{2a} \in \mathbb{R}
\]
   
\[
    p(\lambda) =0 \Leftrightarrow e ^{\lambda x} \text{e' soluzione di (2)}
\]

sia quindi $y(x)$ una soluzione di (2) che scriviamo come:

\[
    y(x) = e ^{\lambda x}u(x) 
\]

Come prima si ottiene:

\[
    e ^{\lambda x}au''(x) = 0
\]

\[
    u''(x) = 0
\]


\[
    u'(x) = c_1
\]

\[
    u(x) = c_1 x +c_2
\]


\end{document}
